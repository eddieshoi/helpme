import streamlit as st
import tensorflow as tf
import keras
from keras import layers
from keras import ops
import numpy as np
from PIL import Image
import os
import gdown

# ==========================================
# 0. ë””ìì¸ ì„¤ì •
# ==========================================
st.set_page_config(page_title="Shadow Play", page_icon="ğŸŒ—", layout="wide")

st.markdown("""
<style>
    @import url('https://cdn.jsdelivr.net/gh/orioncactus/pretendard/dist/web/static/pretendard.css');
    @import url('https://fonts.googleapis.com/css2?family=Playfair+Display:ital,wght@0,400;0,600;1,400&display=swap');

    html, body, [class*="css"] {
        font-family: 'Pretendard', sans-serif;
        background-color: #ffffff;
        color: #1c1917;
    }
    h1, h2, h3 {
        font-family: 'Playfair Display', serif !important;
        font-weight: 400;
    }
    .stButton > button {
        background-color: #111111 !important;
        color: white !important;
        border-radius: 50px !important;
        padding: 10px 30px !important;
        border: none !important;
        transition: transform 0.2s;
    }
    .stButton > button:hover {
        transform: scale(1.02);
        background-color: #333 !important;
    }
    .stFileUploader {
        border: 2px dashed #e5e7eb;
        border-radius: 16px;
        padding: 20px;
        text-align: center;
    }
    header {visibility: hidden;}
    footer {visibility: hidden;}
</style>
""", unsafe_allow_html=True)

# ==========================================
# 1. Custom Layers
# ==========================================
@keras.saving.register_keras_serializable()
class Patches(layers.Layer):
    def __init__(self, patch_size=6, **kwargs):
        super().__init__(**kwargs)
        self.patch_size = patch_size
    def call(self, images):
        input_shape = ops.shape(images)
        batch_size = input_shape[0]
        height = input_shape[1]
        width = input_shape[2]
        channels = input_shape[3]
        num_patches_h = height // self.patch_size
        num_patches_w = width // self.patch_size
        patches = keras.ops.image.extract_patches(images, size=self.patch_size)
        patches = ops.reshape(patches, (batch_size, num_patches_h * num_patches_w, self.patch_size * self.patch_size * channels))
        return patches
    def get_config(self):
        config = super().get_config()
        config.update({"patch_size": self.patch_size})
        return config

@keras.saving.register_keras_serializable()
class PatchEncoder(layers.Layer):
    def __init__(self, num_patches=144, projection_dim=64, **kwargs):
        super().__init__(**kwargs)
        self.num_patches = num_patches
        self.projection_dim = projection_dim
        self.projection = layers.Dense(units=projection_dim)
        self.position_embedding = layers.Embedding(input_dim=num_patches, output_dim=projection_dim)
    def call(self, patch):
        positions = ops.expand_dims(ops.arange(start=0, stop=self.num_patches, step=1), axis=0)
        projected_patches = self.projection(patch)
        encoded = projected_patches + self.position_embedding(positions)
        return encoded
    def get_config(self):
        config = super().get_config()
        config.update({"num_patches": self.num_patches, "projection_dim": self.projection_dim})
        return config

# ==========================================
# 2. ëª¨ë¸ ë¡œë“œ
# ==========================================
@st.cache_resource
def load_model_from_drive():
    # êµ¬ê¸€ ë“œë¼ì´ë¸Œ ID (ìœ ì§€)
    file_id = '1QXUnKa3uCbK7kqgkXULYuEox0HGaE6hy' 
    url = f'https://drive.google.com/uc?id={file_id}'
    output = 'final_model.keras'
    
    if not os.path.exists(output):
        with st.spinner('ëª¨ë¸ íŒŒì¼(248MB)ì„ ë‹¤ìš´ë¡œë“œ ì¤‘ì…ë‹ˆë‹¤... ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”.'):
            gdown.download(url, output, quiet=False)
    
    model = tf.keras.models.load_model(output, custom_objects={'Patches': Patches, 'PatchEncoder': PatchEncoder})
    return model

# ==========================================
# 3. ë©”ì¸ ë¡œì§
# ==========================================
st.markdown("<h1 style='font-size: 3rem; margin-bottom: 0;'>For Visually Impaired,<br>Reading the Emotion Within.</h1>", unsafe_allow_html=True)
st.markdown("<p style='color: #4b5563; margin-bottom: 40px;'>AI-POWERED SHADOW ANALYSIS</p>", unsafe_allow_html=True)

col1, col2 = st.columns([1, 1])

with col1:
    st.markdown("""
    <div style='border-top: 1px solid #e5e5e5; padding-top: 20px; margin-top: 20px;'>
        <p style='font-family: Playfair Display; font-style: italic; color: #9ca3af;'>Discover the unseen</p>
        <p style='line-height: 1.7; color: #4b5563;'>
            Every shadow tells a story. Shadow Play uses advanced AI to reveal the hidden emotional landscape within your images.
        </p>
    </div>
    """, unsafe_allow_html=True)

with col2:
    file = st.file_uploader("Upload Your Image", type=["jpg", "png", "jpeg"])

    if file is not None:
        image = Image.open(file).convert('RGB')
        st.image(image, use_container_width=True)
        
        try:
            model = load_model_from_drive()
            
            if st.button("Analyze Emotion"):
                with st.spinner('Analyzing shadow contours...'):
                    # 1. ì´ë¯¸ì§€ ì „ì²˜ë¦¬ (í•µì‹¬ ìˆ˜ì •!)
                    # / 255.0 ì„ ì œê±°í–ˆìŠµë‹ˆë‹¤. 0~255 ë²”ìœ„ì˜ ê°’ì„ ê·¸ëŒ€ë¡œ ë„£ìŠµë‹ˆë‹¤.
                    img_array = image.resize((224, 224))
                    img_array = np.array(img_array).astype("float32") 
                    # img_array = img_array / 255.0  <-- ì´ ì½”ë“œê°€ ë²”ì¸ì´ì—ˆìŠµë‹ˆë‹¤! ì‚­ì œí•¨.
                    
                    img_array = np.expand_dims(img_array, axis=0)

                    # 2. ì˜ˆì¸¡
                    # Sigmoid ëŒ€ì‹  ë‹¤ì‹œ Softmaxë¥¼ ì“°ê±°ë‚˜, ëª¨ë¸ì˜ ë§ˆì§€ë§‰ ì¸µì— ë”°ë¼ ë‹¤ë¦„
                    # ì¼ë‹¨ logits ê·¸ëŒ€ë¡œ ë°›ì•„ì„œ softmaxë¡œ í™•ë¥ í™”í•˜ëŠ” ê²ƒì´ ê°€ì¥ ì¼ë°˜ì ì…ë‹ˆë‹¤.
                    predictions = model.predict(img_array)
                    probabilities = tf.nn.softmax(predictions).numpy()[0]
                    
                    # ğŸš¨ í´ë˜ìŠ¤ ì´ë¦„ (ì•ŒíŒŒë²³ ìˆœì„œ)
                    class_names = ["calm", "cold", "lonely", "warm"]
                    
                    # 3. ë””ë²„ê¹…ìš© í™•ë¥  ì¶œë ¥ (ê²°ê³¼ê°€ ì´ìƒí•˜ë©´ ì´ ìˆ«ìë¥¼ ë³´ì„¸ìš”)
                    # st.write("ê° ê°ì •ë³„ í™•ë¥ :", {n: float(p) for n, p in zip(class_names, probabilities)})

                    idx = np.argmax(probabilities)
                    emotion = class_names[idx]
                    confidence = probabilities[idx]

                    # 4. ê²°ê³¼ ì¶œë ¥
                    st.divider()
                    if emotion == 'calm':
                        st.markdown("<h2 style='color: #d97706;'>ğŸƒ calm</h2>", unsafe_allow_html=True)
                        st.write("Radiant warmth and joy detected.")
                        st.audio("calm.m4a")
                    elif emotion == 'cold':
                        st.markdown("<h2 style='color: #dc2626;'>ğŸ”¥ cold</h2>", unsafe_allow_html=True)
                        st.write("Freezing cold.")
                        st.audio("sad.m4a") 
                    elif emotion == 'lonely':
                        st.markdown("<h2 style='color: #059669;'>ğŸŒ‘ lonely</h2>", unsafe_allow_html=True)
                        st.write("Lonely.")
                        st.audio("sad.m4a") 
                    elif emotion == 'warm':
                        st.markdown("<h2 style='color: #ea580c;'>ğŸŒ warm</h2>", unsafe_allow_html=True)
                        st.write("Strong energy and intensity detected.")
                        st.audio("happy.m4a") 
                    
                    st.caption(f"Confidence: {confidence*100:.2f}%")

        except Exception as e:
            st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.: {e}")
