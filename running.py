import streamlit as st
import tensorflow as tf
import keras
from keras import layers
from keras import ops
import numpy as np
from PIL import Image
import os

# ==========================================
# 0. ë””ìì¸ ë³µêµ¬ (CSS ê°•ì œ ì£¼ì…)
# ì›ë˜ ë§Œë“œì‹  style.css ëŠë‚Œì„ ë‚´ê¸° ìœ„í•´ ìŠ¤íƒ€ì¼ì„ ì…í™ë‹ˆë‹¤.
# ==========================================
st.set_page_config(page_title="Shadow Play", page_icon="ğŸŒ—", layout="wide")

st.markdown("""
<style>
    @import url('https://cdn.jsdelivr.net/gh/orioncactus/pretendard/dist/web/static/pretendard.css');
    @import url('https://fonts.googleapis.com/css2?family=Playfair+Display:ital,wght@0,400;0,600;1,400&display=swap');

    /* ì „ì²´ í°íŠ¸ ë° ë°°ê²½ ì„¤ì • */
    html, body, [class*="css"] {
        font-family: 'Pretendard', sans-serif;
        background-color: #ffffff;
        color: #1c1917;
    }
    
    /* ì œëª© ìŠ¤íƒ€ì¼ (Playfair Display) */
    h1, h2, h3 {
        font-family: 'Playfair Display', serif !important;
        font-weight: 400;
    }
    
    /* ë²„íŠ¼ ìŠ¤íƒ€ì¼ (ê²€ì€ìƒ‰ ëª¨ë˜í•œ ë²„íŠ¼) */
    .stButton > button {
        background-color: #111111 !important;
        color: white !important;
        border-radius: 50px !important;
        padding: 10px 30px !important;
        border: none !important;
        transition: transform 0.2s;
    }
    .stButton > button:hover {
        transform: scale(1.02);
        background-color: #333 !important;
    }

    /* íŒŒì¼ ì—…ë¡œë” ìŠ¤íƒ€ì¼ */
    .stFileUploader {
        border: 2px dashed #e5e7eb;
        border-radius: 16px;
        padding: 20px;
        text-align: center;
    }

    /* ìƒë‹¨ í—¤ë” ìˆ¨ê¸°ê¸° (ê¹”ë”í•˜ê²Œ) */
    header {visibility: hidden;}
    footer {visibility: hidden;}
</style>
""", unsafe_allow_html=True)

# ==========================================
# 1. ëª¨ë¸ ë¶€í’ˆ (Custom Layer)
# ==========================================
@keras.saving.register_keras_serializable()
class Patches(layers.Layer):
    def __init__(self, patch_size=6, **kwargs):
        super().__init__(**kwargs)
        self.patch_size = patch_size
    def call(self, images):
        input_shape = ops.shape(images)
        batch_size = input_shape[0]
        height = input_shape[1]
        width = input_shape[2]
        channels = input_shape[3]
        num_patches_h = height // self.patch_size
        num_patches_w = width // self.patch_size
        patches = keras.ops.image.extract_patches(images, size=self.patch_size)
        patches = ops.reshape(patches, (batch_size, num_patches_h * num_patches_w, self.patch_size * self.patch_size * channels))
        return patches
    def get_config(self):
        config = super().get_config()
        config.update({"patch_size": self.patch_size})
        return config

@keras.saving.register_keras_serializable()
class PatchEncoder(layers.Layer):
    def __init__(self, num_patches=144, projection_dim=64, **kwargs):
        super().__init__(**kwargs)
        self.num_patches = num_patches
        self.projection_dim = projection_dim
        self.projection = layers.Dense(units=projection_dim)
        self.position_embedding = layers.Embedding(input_dim=num_patches, output_dim=projection_dim)
    def call(self, patch):
        positions = ops.expand_dims(ops.arange(start=0, stop=self.num_patches, step=1), axis=0)
        projected_patches = self.projection(patch)
        encoded = projected_patches + self.position_embedding(positions)
        return encoded
    def get_config(self):
        config = super().get_config()
        config.update({"num_patches": self.num_patches, "projection_dim": self.projection_dim})
        return config

# ==========================================
# 2. ëŒ€ìš©ëŸ‰ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (êµ¬ê¸€ ë“œë¼ì´ë¸Œ)
# ==========================================
import gdown

@st.cache_resource
def load_model_from_drive():
    # ğŸš¨ ì—¬ê¸°ì— ì•„ê¹Œ ë³µì‚¬í•œ êµ¬ê¸€ ë“œë¼ì´ë¸Œ íŒŒì¼ IDë¥¼ ë„£ìœ¼ì„¸ìš”!
    file_id = '1QXUnKa3uCbK7kqgkXULYuEox0HGaE6hy' 
    
    url = f'https://drive.google.com/uc?id={file_id}'
    output = 'final_model.keras'
    
    if not os.path.exists(output):
        with st.spinner('ëª¨ë¸ íŒŒì¼(248MB)ì„ ë‹¤ìš´ë¡œë“œ ì¤‘ì…ë‹ˆë‹¤... ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”.'):
            gdown.download(url, output, quiet=False)
    
    model = tf.keras.models.load_model(output, custom_objects={'Patches': Patches, 'PatchEncoder': PatchEncoder})
    return model

# ==========================================
# 3. í™”ë©´ êµ¬ì„± (ì›ë˜ ë””ìì¸ í‰ë‚´)
# ==========================================

# ì œëª© ì„¹ì…˜
st.markdown("<h1 style='font-size: 3rem; margin-bottom: 0;'>Light and Shadow,<br>Reading the Emotion Within.</h1>", unsafe_allow_html=True)
st.markdown("<p style='color: #4b5563; margin-bottom: 40px;'>AI-POWERED SHADOW ANALYSIS</p>", unsafe_allow_html=True)

col1, col2 = st.columns([1, 1])

with col1:
    st.markdown("""
    <div style='border-top: 1px solid #e5e5e5; padding-top: 20px; margin-top: 20px;'>
        <p style='font-family: Playfair Display; font-style: italic; color: #9ca3af;'>Discover the unseen</p>
        <p style='line-height: 1.7; color: #4b5563;'>
            Every shadow tells a story. Shadow Play uses advanced AI to reveal the hidden emotional landscape within your imagesâ€”transforming light and darkness into profound insight.
        </p>
    </div>
    """, unsafe_allow_html=True)

with col2:
    # íŒŒì¼ ì—…ë¡œë”
    file = st.file_uploader("Upload Your Image", type=["jpg", "png", "jpeg"])

    if file is not None:
        image = Image.open(file).convert('RGB')
        st.image(image, use_container_width=True)
        
        # ëª¨ë¸ ë¡œë“œ ì‹œë„
        try:
            # IDë¥¼ ì…ë ¥í•˜ì§€ ì•Šì•˜ìœ¼ë©´ ê²½ê³ 
            model = load_model_from_drive()
            
            if st.button("Analyze Emotion"):
                with st.spinner('Analyzing shadow contours...'):
                    img_array = image.resize((224, 224))
                    img_array = np.array(img_array).astype("float32") / 255.0
                    img_array = np.expand_dims(img_array, axis=0)

                    logits = model(img_array, training=False)  # shape: (1, num_classes)
                    # 4. softmaxë¡œ í™•ë¥  ê³„ì‚°
                    probs = tf.nn.softmax(logits, axis=-1).numpy()[0]  # (num_classes,)
                    class_names = ["calm", "cold", "lonely", "warm"]

                    # 5. ê°€ì¥ í™•ë¥  ë†’ì€ í´ë˜ìŠ¤ + confidence
                    pred_class = int(np.argmax(probs))
                    confidence = float(probs[pred_class])
                    print(pred_class)
                    print(confidence)

                    print("predicted class index:", pred_class)
                    print("confidence:", confidence)

                    class_names = ["calm", "cold", "lonely", "warm"]
                    print("predicted label:", class_names[pred_class])
                    print("confidence:", float(confidence))

                    predictions = model.predict(img_array)
                    print(predictions)
                    probabilities = tf.nn.softmax(predictions).numpy()[0]
                    class_names = ["calm", "cold", "lonely", "warm"] # ìˆœì„œ í™•ì¸ í•„ìš”
                    
                    idx = np.argmax(probabilities)
                    emotion = class_names[idx]
                    
                    # ê²°ê³¼ ë””ìì¸ ###################### ì´ë¶€ë¶„ classì— ë§ê²Œ modify í•„ìš”í•©ë‹ˆë‹¤.
                    st.divider()
                    if emotion == 'calm':
                        st.markdown("<h2 style='color: #d97706;'>ğŸƒ calm</h2>", unsafe_allow_html=True)
                        st.write("Radiant warmth and joy detected.")
                        st.audio("calm.m4a")
                    elif emotion == 'warm':
                        st.markdown("<h2 style='color: #dc2626;'>ğŸ”¥ warm</h2>", unsafe_allow_html=True)
                        st.write("Strong energy and intensity detected.")
                        st.audio("calm.m4a")
                    elif emotion == 'cold':
                        st.markdown("<h2 style='color: #059669;'>ğŸŒ cold</h2>", unsafe_allow_html=True)
                        st.write("Freezing cold.")
                        st.audio("calm.m4a")
                    elif emotion == 'lonely':
                        st.markdown("<h2 style='color: #059669;'>ğŸŒ lonely</h2>", unsafe_allow_html=True)
                        st.write("Lonely.")
                        st.audio("calm.m4a")

        except Exception as e:
            st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤. êµ¬ê¸€ ë“œë¼ì´ë¸Œ IDë¥¼ ì½”ë“œì— ë„£ì—ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”: {e}")