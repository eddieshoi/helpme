import streamlit as st
import tensorflow as tf
import keras
from keras import layers
from keras import ops
import numpy as np
from PIL import Image
import os
import gdown

# ==========================================
# 0. ë””ìì¸ ë° ì„¤ì • (ê±´ë“œë¦¬ì§€ ì•ŠìŒ)
# ==========================================
st.set_page_config(page_title="Shadow Play", page_icon="ğŸŒ—", layout="wide")

st.markdown("""
<style>
    @import url('https://cdn.jsdelivr.net/gh/orioncactus/pretendard/dist/web/static/pretendard.css');
    @import url('https://fonts.googleapis.com/css2?family=Playfair+Display:ital,wght@0,400;0,600;1,400&display=swap');

    html, body, [class*="css"] {
        font-family: 'Pretendard', sans-serif;
        background-color: #ffffff;
        color: #1c1917;
    }
    h1, h2, h3 {
        font-family: 'Playfair Display', serif !important;
        font-weight: 400;
    }
    .stButton > button {
        background-color: #111111 !important;
        color: white !important;
        border-radius: 50px !important;
        padding: 10px 30px !important;
        border: none !important;
        transition: transform 0.2s;
    }
    .stButton > button:hover {
        transform: scale(1.02);
        background-color: #333 !important;
    }
    .stFileUploader {
        border: 2px dashed #e5e7eb;
        border-radius: 16px;
        padding: 20px;
        text-align: center;
    }
    header {visibility: hidden;}
    footer {visibility: hidden;}
</style>
""", unsafe_allow_html=True)

# ==========================================
# 1. Custom Layers (ê±´ë“œë¦¬ì§€ ì•ŠìŒ)
# ==========================================
@keras.saving.register_keras_serializable()
class Patches(layers.Layer):
    def __init__(self, patch_size=6, **kwargs):
        super().__init__(**kwargs)
        self.patch_size = patch_size
    def call(self, images):
        input_shape = ops.shape(images)
        batch_size = input_shape[0]
        height = input_shape[1]
        width = input_shape[2]
        channels = input_shape[3]
        num_patches_h = height // self.patch_size
        num_patches_w = width // self.patch_size
        patches = keras.ops.image.extract_patches(images, size=self.patch_size)
        patches = ops.reshape(patches, (batch_size, num_patches_h * num_patches_w, self.patch_size * self.patch_size * channels))
        return patches
    def get_config(self):
        config = super().get_config()
        config.update({"patch_size": self.patch_size})
        return config

@keras.saving.register_keras_serializable()
class PatchEncoder(layers.Layer):
    def __init__(self, num_patches=144, projection_dim=64, **kwargs):
        super().__init__(**kwargs)
        self.num_patches = num_patches
        self.projection_dim = projection_dim
        self.projection = layers.Dense(units=projection_dim)
        self.position_embedding = layers.Embedding(input_dim=num_patches, output_dim=projection_dim)
    def call(self, patch):
        positions = ops.expand_dims(ops.arange(start=0, stop=self.num_patches, step=1), axis=0)
        projected_patches = self.projection(patch)
        encoded = projected_patches + self.position_embedding(positions)
        return encoded
    def get_config(self):
        config = super().get_config()
        config.update({"num_patches": self.num_patches, "projection_dim": self.projection_dim})
        return config

# ==========================================
# 2. ëª¨ë¸ ë¡œë“œ (ê±´ë“œë¦¬ì§€ ì•ŠìŒ)
# ==========================================
@st.cache_resource
def load_model_from_drive():
    file_id = '1QXUnKa3uCbK7kqgkXULYuEox0HGaE6hy' 
    url = f'https://drive.google.com/uc?id={file_id}'
    output = 'final_model.keras'
    
    if not os.path.exists(output):
        with st.spinner('ëª¨ë¸ íŒŒì¼(248MB)ì„ ë‹¤ìš´ë¡œë“œ ì¤‘ì…ë‹ˆë‹¤... ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”.'):
            gdown.download(url, output, quiet=False)
    
    model = tf.keras.models.load_model(output, custom_objects={'Patches': Patches, 'PatchEncoder': PatchEncoder})
    return model

# ==========================================
# 3. í™”ë©´ êµ¬ì„± ë° ë¡œì§ (ìš”ì²­í•˜ì‹  ë¶€ë¶„ ìˆ˜ì •ë¨)
# ==========================================

st.markdown("<h1 style='font-size: 3rem; margin-bottom: 0;'>For Visually Impaired,<br>Reading the Emotion Within.</h1>", unsafe_allow_html=True)
st.markdown("<p style='color: #4b5563; margin-bottom: 40px;'>AI-POWERED SCENERY ANALYSIS</p>", unsafe_allow_html=True)

col1, col2 = st.columns([1, 1])

with col1:
    st.markdown("""
    <div style='border-top: 1px solid #e5e5e5; padding-top: 20px; margin-top: 20px;'>
        <p style='font-family: Playfair Display; font-style: italic; color: #9ca3af;'>Discover the unseen</p>
        <p style='line-height: 1.7; color: #4b5563;'>
            Every Scenery tells a story. Scenery Analysis uses advanced AI to reveal the hidden emotional landscape wit hin your imagesâ€”transforming light and darkness into profound insight.
        </p>
    </div>
    """, unsafe_allow_html=True)

with col2:
    file = st.file_uploader("Upload Your Image", type=["jpg", "png", "jpeg"])

    if file is not None:
        image = Image.open(file).convert('RGB')
        st.image(image, use_container_width=True)
        
        try:
            model = load_model_from_drive()
            
            if st.button("Analyze Emotion"):
                with st.spinner('Analyzing shadow contours...'):
                    # 1. ì´ë¯¸ì§€ ì „ì²˜ë¦¬
                    # ğŸš¨ [Warm ë¬¸ì œ í•´ê²°] 0~1 ëŒ€ì‹  -1~1 ë²”ìœ„ë¡œ ë³€ê²½ (ìë°”ìŠ¤í¬ë¦½íŠ¸ì™€ í†µì¼)
                    img_array = image.resize((224, 224))
                    img_array = np.array(img_array).astype("float32")
                    img_array = (img_array / 127.5) - 1.0 
                    img_array = np.expand_dims(img_array, axis=0)

                    # 2. Logits ì¶”ì¶œ ë° Sigmoid ë³€í™˜ (ìš”ì²­í•˜ì‹  ë¡œì§ ì ìš©)
                    logits = model(img_array, training=False)
                    probs = tf.nn.sigmoid(logits)
                    probs_np = probs.numpy()[0]
                    
                    class_names = ["calm", "cold", "lonely", "warm"]

                    # 3. í™•ë¥  ì¬ë¶„ë°° ë¡œì§ (ìš”ì²­í•˜ì‹  ì½”ë“œ ê·¸ëŒ€ë¡œ ì‚½ì…)
                    probs_np = probs_np.copy()
                    c = 2  # lonely index
                    
                    if probs_np[c] == probs_np.max():
                        original = probs_np[c]
                        take = probs_np[c] / 2.0
                        probs_np[c] -= take

                        total_other = probs_np.sum() - probs_np[c]
                        if total_other > 0:
                            for i in range(len(probs_np)):
                                if i != c:
                                    probs_np[i] += take * (probs_np[i] / total_other)
                                if i == c:
                                    probs_np[i] += take * (original / total_other)

                    # 4. ìµœì¢… ê²°ê³¼ ê²°ì •
                    prediction = np.argmax(probs_np)
                    emotion = class_names[prediction]
                    
                    # 5. ê²°ê³¼ ë³´ì—¬ì£¼ê¸°
                    st.divider()
                    if emotion == 'calm':
                        st.markdown("<h2 style='color: #d97706;'>ğŸƒ calm</h2>", unsafe_allow_html=True)
                        st.write("Radiant warmth and joy detected.")
                        st.audio("calm.m4a")
                    elif emotion == 'cold':
                        st.markdown("<h2 style='color: #dc2626;'>ğŸ”¥ cold</h2>", unsafe_allow_html=True)
                        st.write("Freezing cold.")
                        st.audio("sad.m4a") # ìŒì•… ë§¤í•‘ í™•ì¸ í•„ìš”
                    elif emotion == 'lonely':
                        st.markdown("<h2 style='color: #059669;'>ğŸŒ‘ lonely</h2>", unsafe_allow_html=True)
                        st.write("Lonely.")
                        st.audio("sad.m4a") # ìŒì•… ë§¤í•‘ í™•ì¸ í•„ìš”
                    elif emotion == 'warm':
                        st.markdown("<h2 style='color: #ea580c;'>ğŸŒ warm</h2>", unsafe_allow_html=True)
                        st.write("Strong energy and intensity detected.")
                        st.audio("warm.m4a") # ìŒì•… ë§¤í•‘ í™•ì¸ í•„ìš”

        except Exception as e:
            st.error(f"ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.: {e}")

